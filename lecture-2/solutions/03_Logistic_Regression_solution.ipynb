{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data[:]\n",
    "y = data.target[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of feature matrix\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique classes\n",
    "\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Neural Network class\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, loss = 2.473506, accuracy = 0.333\n",
      "epoch = 100, loss = 0.512411, accuracy = 0.820\n",
      "epoch = 200, loss = 0.397781, accuracy = 0.953\n",
      "epoch = 300, loss = 0.328598, accuracy = 0.967\n",
      "epoch = 400, loss = 0.277574, accuracy = 0.973\n",
      "epoch = 500, loss = 0.238605, accuracy = 0.973\n",
      "epoch = 600, loss = 0.208492, accuracy = 0.973\n",
      "epoch = 700, loss = 0.184930, accuracy = 0.973\n",
      "epoch = 800, loss = 0.166223, accuracy = 0.973\n",
      "epoch = 900, loss = 0.151139, accuracy = 0.980\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # convert features and target into PyTorch Variable\n",
    "    inputs = Variable(torch.from_numpy(X).float())\n",
    "    targets = Variable(torch.from_numpy(y))\n",
    "\n",
    "    # forward pass\n",
    "    outputs = model.forward(inputs)\n",
    "    \n",
    "    # convert predicted probabilities to class labels\n",
    "    _, predicted_labels = torch.max(outputs.data, 1)\n",
    "\n",
    "    # calculate loss (Cross-Entropy)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # calculate number of correctly predicted data points\n",
    "    corrects = torch.sum(predicted_labels == targets.data).item()\n",
    "    \n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # perform one step in the oposite direction to the gradient (update weights)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # clear gradient values after weights are updated\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        accuracy = corrects / len(X)\n",
    "        print('epoch = {0}, loss = {1:.6f}, accuracy = {2:.3f}'.format(epoch, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
